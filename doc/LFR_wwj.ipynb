{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0e99894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import scipy.optimize as optim\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "from IPython.display import Markdown, display\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as patches\n",
    "from tabulate import tabulate\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa518bf",
   "metadata": {},
   "source": [
    "# Learning fair representations (LFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a16e360",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "481cc63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1947-04-18</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2014-07-07</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-01-21</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>bouthy</td>\n",
       "      <td>pierrelouis</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>Male</td>\n",
       "      <td>1973-01-22</td>\n",
       "      <td>43</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                name   first         last compas_screening_date   sex  \\\n",
       "0   1    miguel hernandez  miguel    hernandez            2013-08-14  Male   \n",
       "1   3         kevon dixon   kevon        dixon            2013-01-27  Male   \n",
       "2   4            ed philo      ed        philo            2013-04-14  Male   \n",
       "3   5         marcu brown   marcu        brown            2013-01-13  Male   \n",
       "4   6  bouthy pierrelouis  bouthy  pierrelouis            2013-03-26  Male   \n",
       "\n",
       "          dob  age          age_cat              race  ...  v_decile_score  \\\n",
       "0  1947-04-18   69  Greater than 45             Other  ...               1   \n",
       "1  1982-01-22   34          25 - 45  African-American  ...               1   \n",
       "2  1991-05-14   24     Less than 25  African-American  ...               3   \n",
       "3  1993-01-21   23     Less than 25  African-American  ...               6   \n",
       "4  1973-01-22   43          25 - 45             Other  ...               1   \n",
       "\n",
       "   v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
       "0           Low        2013-08-14  2014-07-07   2014-07-14               0   \n",
       "1           Low        2013-01-27  2013-01-26   2013-02-05               0   \n",
       "2           Low        2013-04-14  2013-06-16   2013-06-16               4   \n",
       "3        Medium        2013-01-13         NaN          NaN               1   \n",
       "4           Low        2013-03-26         NaN          NaN               2   \n",
       "\n",
       "  start   end event two_year_recid  \n",
       "0     0   327     0              0  \n",
       "1     9   159     1              1  \n",
       "2     0    63     0              1  \n",
       "3     0  1174     0              0  \n",
       "4     0  1102     0              0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b524a9",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f28de950",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = raw_data.loc[raw_data['race'].isin([\"African-American\", \"Caucasian\"])]\n",
    "\n",
    "processed_data = processed_data[['sex', 'age', 'age_cat', 'race', 'decile_score', 'juv_fel_count', 'juv_misd_count', 'juv_other_count',\n",
    "            'priors_count', 'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_charge_degree', 'is_recid', \n",
    "             'score_text', 'two_year_recid']]\n",
    "\n",
    "# If the charge date of a defendants Compas scored crime was not within 30 days from when the person was arrested, \n",
    "# we can assume that because of data quality reasons, that we do not have the right offense.\n",
    "\n",
    "processed_data = processed_data.loc[processed_data['days_b_screening_arrest'] <= 30]\n",
    "processed_data = processed_data.loc[processed_data['days_b_screening_arrest'] >= -30]\n",
    "\n",
    "# The recidivist flag (is_recid) should be -1 if we could not find a compas case at all.\n",
    "\n",
    "processed_data = processed_data.loc[processed_data['is_recid'] != -1]\n",
    "# Ordinary traffic offenses (c_charge_degree = 'O') will not result in Jail time and hence are removed \n",
    "# (only two of them).\n",
    "\n",
    "processed_data = processed_data.loc[processed_data['c_charge_degree'] != 'O']\n",
    "# score_text shouldn't be 'N/A'\n",
    "\n",
    "processed_data = processed_data.loc[processed_data['score_text'] != 'N/A']\n",
    "processed_data['length_of_stay'] = (pd.to_datetime(processed_data['c_jail_out'])-pd.to_datetime(processed_data['c_jail_in'])).apply(lambda x: x.days)\n",
    "processed_data = processed_data.drop(columns=['c_jail_in', 'c_jail_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b0ad239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the values of the sensitive attribute race as follows: Caucasian -> 1, African-American -> 0\n",
    "processed_data = processed_data.replace({'race': 'Caucasian'}, 1)\n",
    "processed_data = processed_data.replace({'race': 'African-American'}, 0)\n",
    "# replace the values of sex as follows\n",
    "processed_data = processed_data.replace({'sex': 'Male'}, 1)\n",
    "processed_data = processed_data.replace({'sex': 'Female'}, 0)\n",
    "\n",
    "# replace the values of age_cat as follows\n",
    "processed_data = processed_data.replace({'age_cat': 'Less than 25'}, 0)\n",
    "processed_data = processed_data.replace({'age_cat': '25 - 45'}, 1)\n",
    "processed_data = processed_data.replace({'age_cat': 'Greater than 45'}, 2)\n",
    "\n",
    "# replace the values of c_charge_degree as follows\n",
    "processed_data = processed_data.replace({'c_charge_degree': 'F'}, 0)\n",
    "processed_data = processed_data.replace({'c_charge_degree': 'M'}, 1)\n",
    "\n",
    "# replace the values of score_text as follows\n",
    "processed_data = processed_data.replace({'score_text': 'Low'}, 0)\n",
    "processed_data = processed_data.replace({'score_text': 'Medium'}, 1)\n",
    "processed_data = processed_data.replace({'score_text': 'High'}, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e21b4b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_4f0f0_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >column name</th>\n",
       "      <th class=\"col_heading level0 col1\" ># of unique values</th>\n",
       "      <th class=\"col_heading level0 col2\" ># of NaN values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_4f0f0_row0_col0\" class=\"data row0 col0\" >sex</td>\n",
       "      <td id=\"T_4f0f0_row0_col1\" class=\"data row0 col1\" >2</td>\n",
       "      <td id=\"T_4f0f0_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4f0f0_row1_col0\" class=\"data row1 col0\" >age</td>\n",
       "      <td id=\"T_4f0f0_row1_col1\" class=\"data row1 col1\" >62</td>\n",
       "      <td id=\"T_4f0f0_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4f0f0_row2_col0\" class=\"data row2 col0\" >age_cat</td>\n",
       "      <td id=\"T_4f0f0_row2_col1\" class=\"data row2 col1\" >3</td>\n",
       "      <td id=\"T_4f0f0_row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4f0f0_row3_col0\" class=\"data row3 col0\" >race</td>\n",
       "      <td id=\"T_4f0f0_row3_col1\" class=\"data row3 col1\" >2</td>\n",
       "      <td id=\"T_4f0f0_row3_col2\" class=\"data row3 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4f0f0_row4_col0\" class=\"data row4 col0\" >decile_score</td>\n",
       "      <td id=\"T_4f0f0_row4_col1\" class=\"data row4 col1\" >10</td>\n",
       "      <td id=\"T_4f0f0_row4_col2\" class=\"data row4 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4f0f0_row5_col0\" class=\"data row5 col0\" >juv_fel_count</td>\n",
       "      <td id=\"T_4f0f0_row5_col1\" class=\"data row5 col1\" >9</td>\n",
       "      <td id=\"T_4f0f0_row5_col2\" class=\"data row5 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4f0f0_row6_col0\" class=\"data row6 col0\" >juv_misd_count</td>\n",
       "      <td id=\"T_4f0f0_row6_col1\" class=\"data row6 col1\" >10</td>\n",
       "      <td id=\"T_4f0f0_row6_col2\" class=\"data row6 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4f0f0_row7_col0\" class=\"data row7 col0\" >juv_other_count</td>\n",
       "      <td id=\"T_4f0f0_row7_col1\" class=\"data row7 col1\" >8</td>\n",
       "      <td id=\"T_4f0f0_row7_col2\" class=\"data row7 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4f0f0_row8_col0\" class=\"data row8 col0\" >priors_count</td>\n",
       "      <td id=\"T_4f0f0_row8_col1\" class=\"data row8 col1\" >36</td>\n",
       "      <td id=\"T_4f0f0_row8_col2\" class=\"data row8 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4f0f0_row9_col0\" class=\"data row9 col0\" >days_b_screening_arrest</td>\n",
       "      <td id=\"T_4f0f0_row9_col1\" class=\"data row9 col1\" >56</td>\n",
       "      <td id=\"T_4f0f0_row9_col2\" class=\"data row9 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4f0f0_row10_col0\" class=\"data row10 col0\" >c_charge_degree</td>\n",
       "      <td id=\"T_4f0f0_row10_col1\" class=\"data row10 col1\" >2</td>\n",
       "      <td id=\"T_4f0f0_row10_col2\" class=\"data row10 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4f0f0_row11_col0\" class=\"data row11 col0\" >is_recid</td>\n",
       "      <td id=\"T_4f0f0_row11_col1\" class=\"data row11 col1\" >2</td>\n",
       "      <td id=\"T_4f0f0_row11_col2\" class=\"data row11 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4f0f0_row12_col0\" class=\"data row12 col0\" >score_text</td>\n",
       "      <td id=\"T_4f0f0_row12_col1\" class=\"data row12 col1\" >3</td>\n",
       "      <td id=\"T_4f0f0_row12_col2\" class=\"data row12 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4f0f0_row13_col0\" class=\"data row13 col0\" >two_year_recid</td>\n",
       "      <td id=\"T_4f0f0_row13_col1\" class=\"data row13 col1\" >2</td>\n",
       "      <td id=\"T_4f0f0_row13_col2\" class=\"data row13 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4f0f0_row14_col0\" class=\"data row14 col0\" >length_of_stay</td>\n",
       "      <td id=\"T_4f0f0_row14_col1\" class=\"data row14 col1\" >232</td>\n",
       "      <td id=\"T_4f0f0_row14_col2\" class=\"data row14 col2\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1768ebf2d00>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check whether there are NaN values in the final dataset as well as the number of unique values per column\n",
    "\n",
    "unique_NAN_df = pd.DataFrame(columns=['column name', '# of unique values', '# of NaN values'])\n",
    "for item in processed_data.columns:\n",
    "    unique_NAN_df = unique_NAN_df.append({\n",
    "        'column name': item, \n",
    "        '# of unique values': len(processed_data[item].unique()),\n",
    "        '# of NaN values': sum(processed_data[item].isna() == True)}, ignore_index = True)\n",
    "    \n",
    "unique_NAN_df = unique_NAN_df.style.hide_index()\n",
    "unique_NAN_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4818b4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move two_year_recid to the end\n",
    "\n",
    "cols = list(processed_data.columns.values)\n",
    "cols.pop(cols.index('two_year_recid'))\n",
    "processed_data = processed_data[cols+['two_year_recid']]\n",
    "# move race to the first column\n",
    "\n",
    "race_column = processed_data.pop('race')\n",
    "processed_data.insert(0, 'race', race_column)\n",
    "\n",
    "processed_data = processed_data.drop(columns=['age', 'juv_fel_count', 'juv_misd_count', 'juv_other_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "304032ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.to_csv(\"../processed-compas-scores-two-years.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20689d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(processed_data)\n",
    "y = np.array(data[:,-1]).flatten()\n",
    "data = data[:,:-1]\n",
    "sensitive = data[:,0]\n",
    "data = preprocessing.scale(data)\n",
    "data = data[:,1:]\n",
    "\n",
    "# Split data into sensitive and nonsensitive data (sensitive --> race: Caucasian)\n",
    "\n",
    "sensitive_idx = np.array(np.where(sensitive==1))[0].flatten()\n",
    "nonsensitive_idx = np.array(np.where(sensitive!=1))[0].flatten()\n",
    "data_sensitive = data[sensitive_idx,:]\n",
    "data_nonsensitive = data[nonsensitive_idx,:]\n",
    "y_sensitive = y[sensitive_idx]\n",
    "y_nonsensitive = y[nonsensitive_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c00b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split sensitive data into training, validation, and testing sets\n",
    "\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(data_sensitive, y_sensitive, test_size= 0.2, random_state=42)\n",
    "X_train_s, X_valid_s, y_train_s, y_valid_s = train_test_split(X_train_s, y_train_s, test_size = 0.25, random_state=42)\n",
    "# split non-sensitive data into training, validation, and testing sets\n",
    "\n",
    "X_train_n, X_test_n, y_train_n, y_test_n = train_test_split(data_nonsensitive, y_nonsensitive, test_size= 0.2, random_state=42)\n",
    "X_train_n, X_valid_n, y_train_n, y_valid_n = train_test_split(X_train_n, y_train_n, test_size = 0.25, random_state=42)\n",
    "# create final training, validation, and testing sets\n",
    "\n",
    "X_train = np.concatenate((X_train_s, X_train_n))\n",
    "X_valid = np.concatenate((X_valid_s, X_valid_n))\n",
    "X_test = np.concatenate((X_test_s, X_test_n))\n",
    "\n",
    "Y_train = np.concatenate((y_train_s, y_train_n))\n",
    "Y_valid = np.concatenate((y_valid_s, y_valid_n))\n",
    "Y_test = np.concatenate((y_test_s, y_test_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19914dd",
   "metadata": {},
   "source": [
    "## LFR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca1589ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function returns the distance matrix\n",
    "def distances(X, v, alpha, N, P, k):\n",
    "    dists = np.zeros((N, k))\n",
    "    for i in range(N):\n",
    "        for p in range(P):\n",
    "            for j in range(k):    \n",
    "                dists[i, j] += (X[i, p] - v[j, p]) * (X[i, p] - v[j, p]) * alpha[p]\n",
    "    return dists\n",
    "\n",
    "# this function returns the M_nk\n",
    "def M_nk(dists, N, k):\n",
    "    M_nk = np.zeros((N, k))\n",
    "    exp = np.zeros((N, k))\n",
    "    denom = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        for j in range(k):\n",
    "            exp[i, j] = np.exp(-1 * dists[i, j])\n",
    "            denom[i] += exp[i, j]\n",
    "        for j in range(k):\n",
    "            if denom[i]:\n",
    "                M_nk[i, j] = exp[i, j] / denom[i]\n",
    "            else:\n",
    "                M_nk[i, j] = exp[i, j] / 1e-6\n",
    "    return M_nk\n",
    " \n",
    "# this function returns the M_k array\n",
    "def M_k(M_nk, N, k):\n",
    "    M_k = np.zeros(k)\n",
    "    for j in range(k):\n",
    "        for i in range(N):\n",
    "            M_k[j] += M_nk[i, j]\n",
    "        M_k[j] /= N\n",
    "    return M_k\n",
    "\n",
    "# this function reconstructs of X to x_n_hat and L_x\n",
    "def x_n_hat(X, M_nk, v, N, P, k):\n",
    "    x_n_hat = np.zeros((N, P))\n",
    "    L_x = 0.0\n",
    "    for i in range(N):\n",
    "        for p in range(P):\n",
    "            for j in range(k):\n",
    "                x_n_hat[i, p] += M_nk[i, j] * v[j, p]\n",
    "            L_x += (X[i, p] - x_n_hat[i, p]) * (X[i, p] - x_n_hat[i, p])\n",
    "    return x_n_hat, L_x\n",
    "\n",
    "# this function returns a list of prediction\n",
    "def yhat(M_nk, y, w, N, k):\n",
    "    yhat = np.zeros(N)\n",
    "    L_y = 0.0\n",
    "    for i in range(N):\n",
    "        for j in range(k):\n",
    "            yhat[i] += M_nk[i, j] * w[j]\n",
    "        yhat[i] = 1e-6 if yhat[i] <= 0 else yhat[i]\n",
    "        yhat[i] = 0.999 if yhat[i] >= 1 else yhat[i]\n",
    "        L_y += -1 * y[i] * np.log(yhat[i]) - (1.0 - y[i]) * np.log(1.0 - yhat[i])\n",
    "    return yhat, L_y\n",
    "\n",
    "\n",
    "# this function returns the objective function we want to minimize\n",
    "def LFR_objective(params, data_sensitive, data_nonsensitive, y_sensitive, \n",
    "        y_nonsensitive,  k=10, A_x = 1e-4, A_y = 0.1, A_z = 1000):\n",
    "    LFR_objective.iters += 1 \n",
    "    Ns, P = data_sensitive.shape\n",
    "    Nns, _ = data_nonsensitive.shape\n",
    "    \n",
    "    alpha0 = params[:P]\n",
    "    alpha1 = params[P : 2 * P]\n",
    "    w = params[2 * P : (2 * P) + k]\n",
    "    v = np.matrix(params[(2 * P) + k:]).reshape((k, P))\n",
    "        \n",
    "    dists_sensitive = distances(data_sensitive, v, alpha0, Ns, P, k)\n",
    "    dists_nonsensitive = distances(data_nonsensitive, v, alpha1, Nns, P, k)\n",
    "\n",
    "    M_nk_sensitive = M_nk(dists_sensitive, Ns, k)\n",
    "    M_nk_nonsensitive = M_nk(dists_nonsensitive, Nns, k)\n",
    "    \n",
    "    M_k_sensitive = M_k(M_nk_sensitive, Ns, k)\n",
    "    M_k_nonsensitive = M_k(M_nk_nonsensitive, Nns, k)\n",
    "    \n",
    "    L_z = 0.0\n",
    "    for j in range(k):\n",
    "        L_z += abs(M_k_sensitive[j] - M_k_nonsensitive[j])\n",
    "\n",
    "    x_n_hat_sensitive, L_x_sen = x_n_hat(data_sensitive, M_nk_sensitive, v, Ns, P, k)\n",
    "    x_n_hat_nonsensitive, L_x_nsen = x_n_hat(data_nonsensitive, M_nk_nonsensitive, v, Nns, P, k)\n",
    "    L_x = L_x_sen + L_x_nsen\n",
    "\n",
    "    yhat_sensitive, L_y_sen = yhat(M_nk_sensitive, y_sensitive, w, Ns, k)\n",
    "    yhat_nonsensitive, L_y_nsen = yhat(M_nk_nonsensitive, y_nonsensitive, w, Nns, k)\n",
    "    L_y = L_y_sen + L_y_nsen\n",
    "\n",
    "    objective = A_x * L_x + A_y * L_y + A_z * L_z\n",
    "\n",
    "    return objective\n",
    "\n",
    "LFR_objective.iters = 0\n",
    "\n",
    "def LFR(X_train_s, X_train_n, y_train_s, y_train_n, K=10, A_x = 1e-4, A_y = 0.1, A_z = 1000, iter = 100):\n",
    "    rez = np.random.uniform(size=X_train_s.shape[1] * 2 + K + X_train_s.shape[1] * K)\n",
    "    bnd = []\n",
    "    for i, k2 in enumerate(rez):\n",
    "        if i < X_train_s.shape[1] * 2 or i >= X_train_s.shape[1] * 2 + K:\n",
    "            bnd.append((None, None))\n",
    "        else:\n",
    "            bnd.append((0, 1))\n",
    "    \n",
    "    # minimize the metric by parameters alpha, w and v\n",
    "    para, min_L, d = optim.fmin_l_bfgs_b(LFR_objective, x0=rez, epsilon=1e-5, \n",
    "                                         args=(X_train_s, X_train_n, y_train_s, y_train_n, K, A_z, A_x, A_y), \n",
    "                                         bounds = bnd, approx_grad=True, \n",
    "                                         maxfun=iter, maxiter=iter)\n",
    "    \n",
    "    return para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47b813d",
   "metadata": {},
   "source": [
    "## Evaluation Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95ee1c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function defines the threshold for y_n_hat to be 0 or 1\n",
    "def predic_category(y):\n",
    "    for i in range(len(y)):\n",
    "        if y[i] >= 0.5:\n",
    "            y[i] = 1\n",
    "        else:\n",
    "            y[i] = 0\n",
    "    return y\n",
    "\n",
    "# this function calculate y_n_hat by using the best parameters\n",
    "def predict(params, data_sensitive, data_nonsensitive, k=10):\n",
    "    \n",
    "    Ns, P = data_sensitive.shape\n",
    "    Nns, _ = data_nonsensitive.shape\n",
    "    \n",
    "    # form parameters in new forms\n",
    "    alpha0 = params[:P]\n",
    "    alpha1 = params[P : 2 * P]\n",
    "    w = params[2 * P : (2 * P) + k]\n",
    "    v = np.matrix(params[(2 * P) + k:]).reshape((k, P))\n",
    "    \n",
    "    dists_sensitive = distances(data_sensitive, v, alpha0, Ns, P, k)\n",
    "    dists_nonsensitive = distances(data_nonsensitive, v, alpha1, Nns, P, k)\n",
    "\n",
    "    M_nk_sensitive = M_nk(dists_sensitive, Ns, k)\n",
    "    M_nk_nonsensitive = M_nk(dists_nonsensitive, Nns, k)\n",
    "    \n",
    "    M_k_sensitive = M_k(M_nk_sensitive, Ns, k)\n",
    "    M_k_nonsensitive = M_k(M_nk_nonsensitive, Nns, k)\n",
    "    \n",
    "    # make predictions for sensitive data\n",
    "    yhat_sensitive = np.zeros(Ns)\n",
    "    for i in range(Ns):\n",
    "        for j in range(k):\n",
    "            yhat_sensitive[i] += M_nk_sensitive[i, j] * w[j]\n",
    "        yhat_sensitive[i] = 1e-6 if yhat_sensitive[i] <= 0 else yhat_sensitive[i]\n",
    "        yhat_sensitive[i] = 0.999 if yhat_sensitive[i] >= 1 else yhat_sensitive[i]\n",
    "        \n",
    "    # make predictions for nonsensitive data\n",
    "    yhat_nonsensitive = np.zeros(Nns)\n",
    "    for i in range(Nns):\n",
    "        for j in range(k):\n",
    "            yhat_nonsensitive[i] += M_nk_nonsensitive[i, j] * w[j]\n",
    "        yhat_nonsensitive[i] = 1e-6 if yhat_nonsensitive[i] <= 0 else yhat_nonsensitive[i]\n",
    "        yhat_nonsensitive[i] = 0.999 if yhat_nonsensitive[i] >= 1 else yhat_nonsensitive[i]\n",
    "        \n",
    "    final_y_s = predic_category(yhat_sensitive)\n",
    "    final_y_n = predic_category(yhat_nonsensitive)\n",
    "    \n",
    "    return final_y_s, final_y_n\n",
    "\n",
    "def calc_accuracy(y_sen, y_nsen, y_sen_label, y_nsen_label):\n",
    "    y_sen_df = pd.DataFrame(y_sen)\n",
    "    y_nsen_df = pd.DataFrame(y_nsen)\n",
    "    y_label = pd.DataFrame(y_sen_label).append(pd.DataFrame(y_nsen_label))\n",
    "    y_df = y_sen_df.append(y_nsen_df)\n",
    "    \n",
    "    acc_sen = accuracy_score(y_sen_label, y_sen_df)\n",
    "    acc_nsen = accuracy_score(y_nsen_label, y_nsen_df)\n",
    "    total_accuracy = accuracy_score(y_label, y_df)\n",
    "    \n",
    "    return acc_sen, acc_nsen, total_accuracy\n",
    "\n",
    "def calc_calibration(acc_sen, acc_nsen):\n",
    "    return abs(acc_sen - acc_nsen)\n",
    "\n",
    "def get_model_performance(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    matrix = confusion_matrix(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    return accuracy, matrix, f1\n",
    "\n",
    "def plot_model_performance(y_pred_s, y_pred_n, y_pred, y_true_s, y_true_n, y_true):\n",
    "    accuracy_s, matrix_s, f1_s = get_model_performance(y_true_s, y_pred_s)\n",
    "\n",
    "    display(Markdown('#### Sensitive data (Caucasians):'))\n",
    "    print(f'Accuracy: {accuracy_s}')\n",
    "    print(f'F1 score: {f1_s}')\n",
    "    \n",
    "    accuracy_n, matrix_n, f1_n = get_model_performance(y_true_n, y_pred_n)\n",
    "\n",
    "    display(Markdown('#### Nonsensitive data (African-Americans):'))\n",
    "    print(f'Accuracy: {accuracy_n}')\n",
    "    print(f'F1 score: {f1_n}')\n",
    "    \n",
    "    accuracy, matrix, f1 = get_model_performance(y_true, y_pred)\n",
    "\n",
    "    display(Markdown('#### All data:'))\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'F1 score: {f1}')\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 6))\n",
    "    ax = fig.add_subplot(1, 3, 1)\n",
    "    sns.heatmap(matrix_s, annot=True, cmap='Blues', fmt='g')\n",
    "    plt.title('Confusion Matrix (sensitive data)')\n",
    "    \n",
    "    ax = fig.add_subplot(1, 3, 2)\n",
    "    sns.heatmap(matrix_n, annot=True, cmap='Blues', fmt='g')\n",
    "    plt.title('Confusion Matrix (nonsensitive data)')\n",
    "    \n",
    "    ax = fig.add_subplot(1, 3, 3)\n",
    "    sns.heatmap(matrix, annot=True, cmap='Blues', fmt='g')\n",
    "    plt.title('Confusion Matrix (all data)')\n",
    "    \n",
    "def equal_opportunity_difference(y_test_s, y_test_n, pred_test_s, pred_test_n):\n",
    "    tpr_s = 0\n",
    "    for i in range(len(y_test_s)):\n",
    "        if y_test_s[i] == 1 and pred_test_s[i] == 1:\n",
    "            tpr_s += 1 \n",
    "    tpr_s = tpr_s/len(y_test_s)\n",
    "    tpr_n = 0\n",
    "    for i in range(len(y_test_n)):\n",
    "        if y_test_n[i] == 1 and pred_test_n[i] == 1:\n",
    "            tpr_n += 1 \n",
    "    tpr_n = tpr_n/len(y_test_n)\n",
    "    \n",
    "    equal_opportunity_difference = tpr_s - tpr_n\n",
    "    \n",
    "    return equal_opportunity_difference\n",
    "\n",
    "def avg_abs_odds_difference(y_test_s, y_test_n, pred_test_s, pred_test_n):\n",
    "    tpr_s = 0\n",
    "    for i in range(len(y_test_s)):\n",
    "        if y_test_s[i] == 1 and pred_test_s[i] == 1:\n",
    "            tpr_s += 1 \n",
    "    tpr_s = tpr_s/len(y_test_s)\n",
    "    tpr_n = 0\n",
    "    for i in range(len(y_test_n)):\n",
    "        if y_test_n[i] == 1 and pred_test_n[i] == 1:\n",
    "            tpr_n += 1 \n",
    "    tpr_n = tpr_n/len(y_test_n)\n",
    "    \n",
    "    fpr_s = 0\n",
    "    for i in range(len(y_test_s)):\n",
    "        if y_test_s[i] == 0 and pred_test_s[i] == 1:\n",
    "            fpr_s += 1 \n",
    "    fpr_s = fpr_s/len(y_test_s)\n",
    "    fpr_n = 0\n",
    "    for i in range(len(y_test_n)):\n",
    "        if y_test_n[i] == 0 and pred_test_n[i] == 1:\n",
    "            fpr_n += 1 \n",
    "    fpr_n = fpr_n/len(y_test_n)\n",
    "    \n",
    "    avg_abs_odds_diff = 0.5*(abs(fpr_s - fpr_n) + abs(tpr_s - tpr_n))\n",
    "    \n",
    "    return avg_abs_odds_diff\n",
    "\n",
    "def fair_metrics(pred_test_s, pred_test_n, pred_test, y_test_s, y_test_n, y_test):\n",
    "    \n",
    "    cols = ['calibration', 'equal_opportunity_difference', 'average_abs_odds_difference',  'disparate_impact']\n",
    "    obj_fairness = [[0,0,0,1]]\n",
    "    \n",
    "    fair_metrics = pd.DataFrame(data=obj_fairness, index=['objective'], columns=cols)\n",
    "    \n",
    "    acc_sen, acc_nsen, total_accuracy = calc_accuracy(pred_test_s, pred_test_n, y_test_s, y_test_n)\n",
    "    \n",
    "    calibration = acc_sen - acc_nsen\n",
    "    \n",
    "    equal_opp_diff = equal_opportunity_difference(y_test_s, y_test_n, pred_test_s, pred_test_n)\n",
    "    \n",
    "    avg_abs_odds_diff = avg_abs_odds_difference(y_test_s, y_test_n, pred_test_s, pred_test_n)\n",
    "    \n",
    "    disparate_impact = acc_sen/acc_nsen\n",
    "    \n",
    "    row = pd.DataFrame([[calibration, equal_opp_diff, avg_abs_odds_diff, disparate_impact]],\n",
    "                           columns  = cols,\n",
    "                           index = ['Race']\n",
    "                          )\n",
    "    \n",
    "    fair_metrics = fair_metrics.append(row)\n",
    "    fair_metrics = fair_metrics.replace([-np.inf, np.inf], 2)\n",
    "    \n",
    "    return fair_metrics\n",
    "\n",
    "def plot_fair_metrics(fair_metrics):\n",
    "    fig, ax = plt.subplots(figsize=(20,4), ncols=5, nrows=1)\n",
    "\n",
    "    plt.subplots_adjust(\n",
    "        left    =  0.125, \n",
    "        bottom  =  0.1, \n",
    "        right   =  0.9, \n",
    "        top     =  0.9, \n",
    "        wspace  =  .5, \n",
    "        hspace  =  1.1\n",
    "    )\n",
    "\n",
    "    y_title_margin = 1.2\n",
    "\n",
    "    plt.suptitle(\"Fairness metrics\", y = 1.09, fontsize=20)\n",
    "    sns.set(style=\"dark\")\n",
    "\n",
    "    cols = fair_metrics.columns.values\n",
    "    obj = fair_metrics.loc['objective']\n",
    "    size_rect = [0.2,0.2,0.2,0.4]\n",
    "    rect = [-0.1,-0.1,-0.1,0.8]\n",
    "    bottom = [-1,-1,-1,0]\n",
    "    top = [1,1,1,2]\n",
    "    bound = [[-0.1,0.1],[-0.1,0.1],[-0.1,0.1],[0.8,1.2]]\n",
    "\n",
    "    display(Markdown(\"### Check bias metrics :\"))\n",
    "    display(Markdown(\"A model can be considered bias if just one of these four metrics show that this model is biased.\"))\n",
    "    for attr in fair_metrics.index[1:len(fair_metrics)].values:\n",
    "        display(Markdown(\"#### For the %s attribute :\"%attr))\n",
    "        check = [bound[i][0] < fair_metrics.loc[attr][i] < bound[i][1] for i in range(0,4)]\n",
    "        display(Markdown(\"With default thresholds, bias against unprivileged group detected in **%d** out of 4 metrics\"%(4 - sum(check))))\n",
    "\n",
    "    for i in range(0,4):\n",
    "        plt.subplot(1, 4, i+1)\n",
    "        ax = sns.barplot(x=fair_metrics.index[1:len(fair_metrics)], y=fair_metrics.iloc[1:len(fair_metrics)][cols[i]])\n",
    "        \n",
    "        for j in range(0,len(fair_metrics)-1):\n",
    "            a, val = ax.patches[j], fair_metrics.iloc[j+1][cols[i]]\n",
    "            marg = -0.2 if val < 0 else 0.1\n",
    "            ax.text(a.get_x()+a.get_width()/4, a.get_y()+a.get_height()+marg, round(val, 3), fontsize=15,color='black')\n",
    "\n",
    "        plt.ylim(bottom[i], top[i])\n",
    "        plt.setp(ax.patches, linewidth=0)\n",
    "        ax.add_patch(patches.Rectangle((-5,rect[i]), 10, size_rect[i], alpha=0.3, facecolor=\"green\", linewidth=1, linestyle='solid'))\n",
    "        plt.axhline(obj[i], color='black', alpha=0.3)\n",
    "        plt.title(cols[i])\n",
    "        ax.set_ylabel('')    \n",
    "        ax.set_xlabel('')\n",
    "\n",
    "def compare_models(pred_1_test_s, pred_1_test_n, pred_2_test_s, pred_2_test_n, y_test_s, y_test_n, y_PR_test_s, y_PR_test_n,\n",
    "                  fair_metrics_1, fair_metrics_2, model1, model2):\n",
    "    acc_1_sen, acc_1_nsen, total_accuracy_1 = calc_accuracy(pred_1_test_s, pred_1_test_n, y_test_s, y_test_n)\n",
    "    acc_2_sen, acc_2_nsen, total_accuracy_2 = calc_accuracy(pred_2_test_s, pred_2_test_n, y_PR_test_s, y_PR_test_n)\n",
    "\n",
    "    calibration_1 = fair_metrics_1.iloc[1]['calibration']\n",
    "    equal_opp_diff_1 = fair_metrics_1.iloc[1]['equal_opportunity_difference']\n",
    "    avg_abs_odds_diff_1 = fair_metrics_1.iloc[1]['average_abs_odds_difference']\n",
    "    disparate_impact_1 = fair_metrics_1.iloc[1]['disparate_impact']\n",
    "\n",
    "    calibration_2 = fair_metrics_2.iloc[1]['calibration']\n",
    "    equal_opp_diff_2 = fair_metrics_2.iloc[1]['equal_opportunity_difference']\n",
    "    avg_abs_odds_diff_2 = fair_metrics_2.iloc[1]['average_abs_odds_difference']\n",
    "    disparate_impact_2 = fair_metrics_2.iloc[1]['disparate_impact']\n",
    "    \n",
    "    print(tabulate([['accuracy', total_accuracy_1, total_accuracy_2], \n",
    "                ['calibration', calibration_1, calibration_2],\n",
    "                ['equal_opportunity_difference', equal_opp_diff_1, equal_opp_diff_2],\n",
    "                ['average_abs_odds_difference', avg_abs_odds_diff_1, avg_abs_odds_diff_2],\n",
    "                ['disparate_impact', disparate_impact_1, disparate_impact_2]], headers=['metric', model1, model2]))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d72a5b",
   "metadata": {},
   "source": [
    "## Implementing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c9c1170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished for 100 iterations in 991.5338418483734 secs\n",
      "Finished for 200 iterations in 621.6066381931305 secs\n",
      "Finished for 300 iterations in 895.771886587143 secs\n",
      "Finished for 400 iterations in 1628.4575157165527 secs\n",
      "Finished for 500 iterations in 2639.538587808609 secs\n"
     ]
    }
   ],
   "source": [
    "iter_max = 500\n",
    "\n",
    "model_train_time = []\n",
    "train_Accuracy = []\n",
    "val_Accuracy = []\n",
    "train_Calibration = []\n",
    "val_Calibration = []\n",
    "\n",
    "best_accuracy = 0\n",
    "\n",
    "for i in range(100, iter_max+100, 100):\n",
    "\n",
    "    #model training\n",
    "    start = time.time()\n",
    "    #random.seed(1024); np.random.seed(1024)\n",
    "    final_parameters = LFR(X_train_s, X_train_n, y_train_s, y_train_n, 10, 1e-4, 0.1, 1000, iter = i)\n",
    "    model_train_time.append(time.time() - start)\n",
    "\n",
    "    #Train set accuracy and calibration\n",
    "    pred_train_s, pred_train_n = predict(final_parameters, X_train_s, X_train_n, 10)\n",
    "    acc_sen, acc_nsen, total_accuracy = calc_accuracy(pred_train_s, pred_train_n, y_train_s, y_train_n)\n",
    "    train_Accuracy.append(total_accuracy)\n",
    "\n",
    "    calibration = calc_calibration(acc_sen, acc_nsen)\n",
    "    train_Calibration.append(calibration)\n",
    "\n",
    "    #Validation set accuracy and calibration\n",
    "    pred_val_s, pred_val_n = predict(final_parameters, X_valid_s, X_valid_n, 10)\n",
    "    acc_sen, acc_nsen, total_accuracy = calc_accuracy(pred_val_s, pred_val_n, y_valid_s, y_valid_n)\n",
    "    val_Accuracy.append(total_accuracy)\n",
    "\n",
    "    calibration = calc_calibration(acc_sen, acc_nsen)\n",
    "    val_Calibration.append(calibration)\n",
    "\n",
    "    if total_accuracy > best_accuracy:\n",
    "        best_accuracy = total_accuracy\n",
    "        best_model = copy.deepcopy(final_parameters)\n",
    "\n",
    "    print(\"Finished for \" + str(i) + \" iterations in \" + str(time.time() - start) + \" secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d2f8a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 200, 300, 400, 500]\n",
      "[989.1727020740509, 619.2910935878754, 894.5519225597382, 1625.0544106960297, 2635.091701745987]\n",
      "[0.5262160454832596, 0.543903979785218, 0.5764371446620341, 0.5906506632975363, 0.3063802905874921]\n",
      "[0.4895833333333333, 0.5539772727272727, 0.5785984848484849, 0.6070075757575758, 0.2793560606060606]\n",
      "[0.04422853170316443, 0.12143260046498949, 0.03705137571522832, 0.0687834718519027, 0.13752281757801685]\n",
      "[0.024153216002394007, 0.137366974021359, 0.08457179194643427, 0.12027979875437189, 0.09720762339386915]\n"
     ]
    }
   ],
   "source": [
    "filename = 'best_model.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))\n",
    "\n",
    "iterations = [i for i in range(100, iter_max+100, 100)]\n",
    "\n",
    "print(iterations)\n",
    "print(model_train_time)\n",
    "print(train_Accuracy)\n",
    "print(val_Accuracy)\n",
    "print(train_Calibration)\n",
    "print(val_Calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "642a27cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'best_model.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0e120a",
   "metadata": {},
   "source": [
    "Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23d3cc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for Caucasians is:  0.6320380650277557\n",
      "The accuracy for African-Americans is:  0.563254593175853\n",
      "The total accuracy is:  0.5906506632975363\n",
      "The calibration is:  0.0687834718519027\n"
     ]
    }
   ],
   "source": [
    "# get predictions for the training dataset\n",
    "\n",
    "pred_train_s, pred_train_n = predict(loaded_model, X_train_s, X_train_n, 10)\n",
    "\n",
    "# get accuracy for the training dataset\n",
    "\n",
    "acc_sen, acc_nsen, total_accuracy = calc_accuracy(pred_train_s, pred_train_n, y_train_s, y_train_n)\n",
    "\n",
    "print(\"The accuracy for Caucasians is: \", acc_sen)\n",
    "print(\"The accuracy for African-Americans is: \", acc_nsen)\n",
    "print(\"The total accuracy is: \", total_accuracy)\n",
    "\n",
    "# get calibration for the training dataset\n",
    "\n",
    "calibration = calc_calibration(acc_sen, acc_nsen)\n",
    "\n",
    "print(\"The calibration is: \", calibration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d273aa10",
   "metadata": {},
   "source": [
    "Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04326adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for Caucasians is:  0.6793349168646081\n",
      "The accuracy for African-Americans is:  0.5590551181102362\n",
      "The total accuracy is:  0.6070075757575758\n",
      "The calibration is:  0.12027979875437189\n"
     ]
    }
   ],
   "source": [
    "# get predictions for the validation dataset\n",
    "\n",
    "pred_val_s, pred_val_n = predict(loaded_model, X_valid_s, X_valid_n, 10)\n",
    "\n",
    "# get accuracy for the validation dataset\n",
    "\n",
    "acc_sen, acc_nsen, total_accuracy = calc_accuracy(pred_val_s, pred_val_n, y_valid_s, y_valid_n)\n",
    "\n",
    "print(\"The accuracy for Caucasians is: \", acc_sen)\n",
    "print(\"The accuracy for African-Americans is: \", acc_nsen)\n",
    "print(\"The total accuracy is: \", total_accuracy)\n",
    "\n",
    "# get calibration for the validation dataset\n",
    "\n",
    "calibration = calc_calibration(acc_sen, acc_nsen)\n",
    "\n",
    "print(\"The calibration is: \", calibration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47939212",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efc2830",
   "metadata": {},
   "source": [
    "Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b81adb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for Caucasians is:  0.6603325415676959\n",
      "The accuracy for African-Americans is:  0.5480314960629922\n",
      "The total accuracy is:  0.5928030303030303\n",
      "The calibration is:  0.11230104550470377\n"
     ]
    }
   ],
   "source": [
    "# get predictions for the testing dataset\n",
    "\n",
    "pred_test_s, pred_test_n = predict(loaded_model, X_test_s, X_test_n, 10)\n",
    "\n",
    "# get accuracy for the testing dataset\n",
    "\n",
    "acc_sen, acc_nsen, total_accuracy = calc_accuracy(pred_test_s, pred_test_n, y_test_s, y_test_n)\n",
    "\n",
    "print(\"The accuracy for Caucasians is: \", acc_sen)\n",
    "print(\"The accuracy for African-Americans is: \", acc_nsen)\n",
    "print(\"The total accuracy is: \", total_accuracy)\n",
    "\n",
    "# get calibration for the testing dataset\n",
    "\n",
    "calibration = calc_calibration(acc_sen, acc_nsen)\n",
    "\n",
    "print(\"The calibration is: \", calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3aa1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
