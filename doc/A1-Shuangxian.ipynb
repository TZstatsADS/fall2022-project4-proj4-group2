{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "import scipy.optimize as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from numpy import mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data=pd.read_csv('/Users/lsx/Desktop/5243project4/data/compas-scores-two-years.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since we are only intersted in sample fairness between two races: African-American and Caucasian\n",
    "#and LFR needs to cageorize sensitive group and nonsensitive group,we regard defandant with African-American as 0,Caucasian as 1\n",
    "data = data[(data['race']=='African-American') | (data['race']=='Caucasian')]\n",
    "data = data.replace({'race': 'Caucasian'}, 1)\n",
    "data = data.replace({'race': 'African-American'}, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop variables with many NAs\n",
    "data=data.drop(columns=['id', 'name', 'first', 'last','compas_screening_date','dob','age','c_jail_in', 'c_jail_out', 'c_case_number','c_offense_date','c_charge_desc', 'c_arrest_date','r_charge_desc',\n",
    "'r_case_number','r_charge_desc','r_offense_date', 'r_jail_in', 'r_jail_out','violent_recid','vr_case_number',\n",
    "'vr_offense_date', 'vr_charge_desc', 'screening_date','v_screening_date','in_custody','out_custody','r_charge_degree','r_days_from_arrest',\n",
    "                      'vr_charge_degree','type_of_assessment','v_type_of_assessment' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6150, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NA \n",
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before building the LFR model, we need to transfer variables to dummy variables .\n",
    "- Split data into Sensitive and Nonsensitive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fk/z7v3jbsd74q31y7nyk6xvmj80000gn/T/ipykernel_25954/3470841975.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['sex'].loc[data['sex']=='Female']= 0\n",
      "/var/folders/fk/z7v3jbsd74q31y7nyk6xvmj80000gn/T/ipykernel_25954/3470841975.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['age_cat'].loc[data['age_cat']=='Greater than 45']= 'C'\n",
      "/var/folders/fk/z7v3jbsd74q31y7nyk6xvmj80000gn/T/ipykernel_25954/3470841975.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['age_cat'].loc[data['age_cat']=='Less than 25']= 'A'\n",
      "/var/folders/fk/z7v3jbsd74q31y7nyk6xvmj80000gn/T/ipykernel_25954/3470841975.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['c_charge_degree'].loc[data['c_charge_degree']=='M']= 1\n",
      "/var/folders/fk/z7v3jbsd74q31y7nyk6xvmj80000gn/T/ipykernel_25954/3470841975.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['c_charge_degree'].loc[data['c_charge_degree']=='F']= 0\n",
      "/var/folders/fk/z7v3jbsd74q31y7nyk6xvmj80000gn/T/ipykernel_25954/3470841975.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['v_score_text'].loc[data['v_score_text']=='High']= 'A'\n",
      "/var/folders/fk/z7v3jbsd74q31y7nyk6xvmj80000gn/T/ipykernel_25954/3470841975.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['v_score_text'].loc[data['v_score_text']=='Medium']= 'B'\n",
      "/var/folders/fk/z7v3jbsd74q31y7nyk6xvmj80000gn/T/ipykernel_25954/3470841975.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['v_score_text'].loc[data['v_score_text']=='Low']= 'C'\n",
      "/var/folders/fk/z7v3jbsd74q31y7nyk6xvmj80000gn/T/ipykernel_25954/3470841975.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['score_text'].loc[data['score_text']=='High']= 'A'\n",
      "/var/folders/fk/z7v3jbsd74q31y7nyk6xvmj80000gn/T/ipykernel_25954/3470841975.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['score_text'].loc[data['score_text']=='Low']= 'B'\n",
      "/var/folders/fk/z7v3jbsd74q31y7nyk6xvmj80000gn/T/ipykernel_25954/3470841975.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['score_text'].loc[data['score_text']=='Medium']= 'C'\n"
     ]
    }
   ],
   "source": [
    "#Encode gender to 0/1\n",
    "data['sex'].loc[data['sex']=='Male']= 1\n",
    "data['sex'].loc[data['sex']=='Female']= 0\n",
    "\n",
    "data['age_cat'].loc[data['age_cat']=='25 - 45']= 'B'\n",
    "data['age_cat'].loc[data['age_cat']=='Greater than 45']= 'C'\n",
    "data['age_cat'].loc[data['age_cat']=='Less than 25']= 'A'\n",
    "data.loc[data['age_cat']=='A', 'age_cat1'] = 1\n",
    "data.loc[data['age_cat']!='A', 'age_cat1'] = 0\n",
    "data.loc[data['age_cat']=='B', 'age_cat2'] = 1\n",
    "data.loc[data['age_cat']!='B', 'age_cat2'] = 0\n",
    "\n",
    "\n",
    "data['c_charge_degree'].loc[data['c_charge_degree']=='M']= 1\n",
    "data['c_charge_degree'].loc[data['c_charge_degree']=='F']= 0\n",
    "\n",
    "data['v_score_text'].loc[data['v_score_text']=='High']= 'A'\n",
    "data['v_score_text'].loc[data['v_score_text']=='Medium']= 'B'\n",
    "data['v_score_text'].loc[data['v_score_text']=='Low']= 'C'\n",
    "data.loc[data['v_score_text']=='A', 'v_score_text1'] = 1\n",
    "data.loc[data['v_score_text']!='A', 'v_score_text1'] = 0\n",
    "data.loc[data['v_score_text']=='B', 'v_score_text2'] = 1\n",
    "data.loc[data['v_score_text']!='B', 'v_score_text2'] = 0\n",
    "\n",
    "\n",
    "data['score_text'].loc[data['score_text']=='High']= 'A'\n",
    "data['score_text'].loc[data['score_text']=='Low']= 'B'\n",
    "data['score_text'].loc[data['score_text']=='Medium']= 'C'\n",
    "data.loc[data['score_text']=='A', 'score_text1'] = 1\n",
    "data.loc[data['score_text']!='A', 'score_text1'] = 0\n",
    "data.loc[data['score_text']=='B', 'score_text2'] = 1\n",
    "data.loc[data['score_text']!='B', 'score_text2'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop original categorical variables\n",
    "data=data.drop(columns=['age_cat','v_score_text','score_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>...</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>age_cat1</th>\n",
       "      <th>age_cat2</th>\n",
       "      <th>v_score_text1</th>\n",
       "      <th>v_score_text2</th>\n",
       "      <th>score_text1</th>\n",
       "      <th>score_text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>747</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>428.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>428</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sex  race  juv_fel_count  decile_score  juv_misd_count  juv_other_count  \\\n",
       "1   1     0              0             3               0                0   \n",
       "2   1     0              0             4               0                1   \n",
       "6   1     1              0             6               0                0   \n",
       "8   0     1              0             1               0                0   \n",
       "9   1     1              0             3               0                0   \n",
       "\n",
       "   priors_count  days_b_screening_arrest  c_days_from_compas c_charge_degree  \\\n",
       "1             0                     -1.0                 1.0               0   \n",
       "2             4                     -1.0                 1.0               0   \n",
       "6            14                     -1.0                 1.0               0   \n",
       "8             0                     -1.0                 1.0               1   \n",
       "9             1                    428.0               308.0               0   \n",
       "\n",
       "   ...  start  end  event  two_year_recid  age_cat1  age_cat2  v_score_text1  \\\n",
       "1  ...      9  159      1               1       0.0       1.0            0.0   \n",
       "2  ...      0   63      0               1       1.0       0.0            0.0   \n",
       "6  ...      5   40      1               1       0.0       1.0            0.0   \n",
       "8  ...      2  747      0               0       0.0       1.0            0.0   \n",
       "9  ...      0  428      1               1       1.0       0.0            0.0   \n",
       "\n",
       "   v_score_text2  score_text1  score_text2  \n",
       "1            0.0          0.0          1.0  \n",
       "2            0.0          0.0          1.0  \n",
       "6            0.0          0.0          0.0  \n",
       "8            0.0          0.0          1.0  \n",
       "9            1.0          0.0          1.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training, validation and testing set (0.6, 0.2, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data, test_size=0.2, random_state=1)\n",
    "data_train, data_val= train_test_split(data_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=pd.concat([data_train.sex,data_train.race,data_train.juv_fel_count,data_train.decile_score,data_train.two_year_recid],axis=1)\n",
    "data_train=data_train.iloc[:20]\n",
    "data_val=pd.concat([data_val.sex,data_val.race,data_val.juv_fel_count,data_val.decile_score,data_val.two_year_recid],axis=1)\n",
    "data_test=pd.concat([data_test.sex,data_test.race,data_test.juv_fel_count,data_test.decile_score,data_test.two_year_recid],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3883</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6410</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sex  race  juv_fel_count  decile_score  two_year_recid\n",
       "246    1     1              0             1               0\n",
       "3883   1     0              0             1               0\n",
       "6410   1     0              0             2               0\n",
       "437    1     1              0            10               1\n",
       "3497   0     1              0            10               1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Fair Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$d(x_n, v_k, \\alpha) = \\sum^D_{d=1} \\alpha_d (x_{nd} - v_{kd})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance - d(x_n, v_k, alpha)\n",
    "def distance(X, v, alpha):\n",
    "    N = X.shape[0]\n",
    "    D = X.shape[1]\n",
    "    K = len(v)\n",
    "\n",
    "    \n",
    "    res = np.zeros((N, K))\n",
    "    \n",
    "    for n in range(N):\n",
    "        for k in range(K):\n",
    "            for d in range(D):\n",
    "                res[n, k] += alpha[d]*(X.iloc[n][d] - v[k, d])**2\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$M_{nk} = P(Z=k|x_n) \\space\\space \\forall n, k \\\\ \n",
    "= exp(-d(x_n, v_k))/\\sum_{k=1}^K exp(-d(x_n, v_k))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M_nk = P(Z=k|x_n)is the probablity that x_n maps to v_k\n",
    "\n",
    "def M_nk(dist, k):\n",
    "    \n",
    "    N = dist.shape[0]\n",
    "    K = dist.shape[1]\n",
    "    M_nk = np.zeros((N, K))\n",
    "    expo_res = np.zeros((N, K))\n",
    "    \n",
    "    for n in range(N):\n",
    "        deno = 0\n",
    "        for k in range(K):\n",
    "            expo_res[n, k] = math.exp((-1)*dist[n, k])\n",
    "            deno += expo_res[n, k]\n",
    "        for k in range(K):\n",
    "            M_nk[n, k] = expo_res[n, k] / deno\n",
    "    return M_nk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$M_k = \\frac{1}{|X_0|} \\sum_{n \\in X_0} M_{nk}$\n",
    "\n",
    "$X_0 = \\{X_0^+, X_0^-\\}$\n",
    "\n",
    "$X_0$ is training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  M_k\n",
    "def M_k(X, M_nk, k):\n",
    "    N = X.shape[0]\n",
    "    K = M_nk.shape[1]\n",
    "    M_k = np.zeros(K)\n",
    "    \n",
    "    for k in range(K):\n",
    "        for n in range(N):\n",
    "            M_k[k] += M_nk[n, k]\n",
    "        M_k[k] = M_k[k]/N\n",
    "    return M_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\hat{x}_n = \\sum^K_{k=1}M_{nk}v_k\n",
    "$\n",
    "\n",
    "$\n",
    "L_x = \\sum_{n=1}^N (x_n - \\hat{x}_n)^2\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  the reconstruction of x_n  and L_x\n",
    "def x_n_hat(X, M_nk, v):\n",
    "\n",
    "    N = M_nk.shape[0]\n",
    "    D = X.shape[1]\n",
    "    K = M_nk.shape[1]\n",
    "    x_n_hat = np.zeros((N, D))\n",
    "    L_x = 0\n",
    "    \n",
    "    \n",
    "    for n in range(N):\n",
    "        for d in range(D):\n",
    "            for k in range(K):\n",
    "                x_n_hat[n, d] += M_nk[n, k]*v[k, d]\n",
    "        # calculate L_x        \n",
    "        L_x += (X.iloc[n][d] - x_n_hat[n, d])**2\n",
    "    \n",
    "    return x_n_hat, L_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "L_y = \\sum_{n=1}^N -y_n log \\hat{y}_n - (1-y_n)log(1- \\hat{y}_n)\n",
    "$\n",
    "\n",
    "\n",
    "minimize $L = A_z L_Z + A_x L_x + A_y L_y$ \n",
    "\n",
    "$A_x, A_z, A_y$ are hyperparameters governing trade-off between the system desiderata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction for y_n and L_y\n",
    "def y_n_hat(M_nk, w, y):\n",
    "    N = M_nk.shape[0]\n",
    "    K = M_nk.shape[1]\n",
    "    y_n_hat = np.zeros(N)\n",
    "    L_y = 0\n",
    "    \n",
    "\n",
    "    for n in range(N):\n",
    "        for k in range(K):\n",
    "            y_n_hat[n] += M_nk[n, k]*w[k]\n",
    "        # calculate L_y\n",
    "        L_y += (-1)*y.iloc[n]*np.log(y_n_hat[n]) - (1 - y.iloc[n])*np.log(1 - y_n_hat[n])\n",
    "        \n",
    "    return y_n_hat, L_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  the metric function we wanna minimize\n",
    "def L(param, sen_df, nsen_df, sen_y, nonsen_y, K, A_z, A_x, A_y):\n",
    "    # param is the list of parameters\n",
    "    # sen_df is the sensitive dataset\n",
    "    # nsen_df is the nonsensitive dataset\n",
    "    # sen_y is the list of labels for sensitive dataset\n",
    "    # nonsen_y is the list of labels for nonsensitive dataset\n",
    "    # K, A_z, A_x and A_y are hyperparameters, the values are decided by the users\n",
    "    \n",
    "    sen_N, sen_D = sen_df.shape\n",
    "    nsen_N, nsen_D = nsen_df.shape\n",
    "\n",
    "   \n",
    "    alpha_sen = param[:sen_D]\n",
    "    alpha_nsen = param[sen_D : 2 * sen_D]\n",
    "    w = param[2 * sen_D : (2 * sen_D) + K]\n",
    "    v = np.matrix(param[(2 * sen_D) + K:]).reshape((K, sen_D))\n",
    "\n",
    "    #  the distance matrix\n",
    "    dist_sen = distance(sen_df, v, alpha_sen)\n",
    "    dist_nsen = distance(nsen_df, v, alpha_nsen)        \n",
    "\n",
    "    # M_nk matrix\n",
    "    M_nk_sen = M_nk(dist_sen, K)\n",
    "    M_nk_nsen = M_nk(dist_nsen, K)\n",
    "\n",
    "    #  M_k matrix\n",
    "    M_k_sen = M_k(sen_df, M_nk_sen, K)\n",
    "    M_k_nsen = M_k(nsen_df, M_nk_nsen, K)\n",
    "\n",
    "    #  L_z\n",
    "    L_z = 0\n",
    "    for k in range(K):\n",
    "        L_z += abs(M_k_sen[k] - M_k_nsen[k])\n",
    "\n",
    "    #  x_n_hat and L_x\n",
    "    x_n_hat_sen, L_x_sen = x_n_hat(sen_df, M_nk_sen, v)\n",
    "    x_n_hat_nsen, L_x_nsen = x_n_hat(nsen_df, M_nk_nsen, v)\n",
    "    L_x = L_x_sen + L_x_nsen\n",
    "\n",
    "    # y_n_hat and L_y\n",
    "    y_hat_sen, L_y_sen = y_n_hat(M_nk_sen, w, sen_y)\n",
    "    y_hat_nsen, L_y_nsen = y_n_hat(M_nk_nsen, w, nonsen_y)\n",
    "    L_y = L_y_sen + L_y_nsen\n",
    "\n",
    "    # the  metric function\n",
    "    metric = A_z*L_z + A_x*L_x + A_y*L_y\n",
    "\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\hat{y}_n = \\sum^K_{k=1} M_{nk}w_k \\\\\n",
    "0< w_k <1\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines the threshold for y_n_hat to be 0 or 1\n",
    "def predic_threshold(preds):\n",
    "    for i in range(len(preds)):\n",
    "        if preds[i] >= 0.5:\n",
    "            preds[i] = 1\n",
    "        else:\n",
    "            preds[i] = 0\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  calculate y_n_hat by using the best parameters\n",
    "def cal_pred(params, D, K, sen_dt, nsen_dt, sen_label, nsen_label):\n",
    "    # form parameters in new forms\n",
    "    best_alpha_sen = params[:D]\n",
    "    best_alpha_nsen = params[D : 2 * D]\n",
    "    best_w = params[2 * D : (2 * D) + K]\n",
    "    best_v = np.matrix(params[(2 * D) + K:]).reshape((K, D))\n",
    "    \n",
    "    # calculate the distance matrix\n",
    "    best_dist_sen = distance(sen_dt, best_v, best_alpha_sen)\n",
    "    best_dist_nsen = distance(nsen_dt, best_v, best_alpha_nsen) \n",
    "    \n",
    "    # calculate the M_nk matrix\n",
    "    best_M_nk_sen = M_nk(best_dist_sen, K)\n",
    "    best_M_nk_nsen = M_nk(best_dist_nsen, K)\n",
    "    \n",
    "    # calculate the y_n_hat matrix\n",
    "    y_hat_sen, L_y_sen = y_n_hat(best_M_nk_sen, best_w, sen_label)\n",
    "    y_hat_nsen, L_y_nsen = y_n_hat(best_M_nk_nsen, best_w, nsen_label)\n",
    "    \n",
    "    return y_hat_sen, y_hat_nsen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  calculates the  overall accuracy, \n",
    "# accuracy for  African-American group\n",
    "# accuracy for  Caucasian group\n",
    "# and calibration of the model\n",
    "def cal_calibr(y_pred_sen, y_pred_nsen, y_sen_label, y_nsen_label):\n",
    "    converted_y_hat_sen = predic_threshold(y_pred_sen)\n",
    "    converted_y_hat_nsen = predic_threshold(y_pred_nsen)\n",
    "\n",
    "    y_pred_sen = pd.DataFrame(converted_y_hat_sen)\n",
    "    y_pred_nsen = pd.DataFrame(converted_y_hat_nsen)\n",
    "     \n",
    "    # calculate the accuracy\n",
    "    acc_sen = accuracy_score(y_sen_label, y_pred_sen)\n",
    "    acc_nsen = accuracy_score(y_nsen_label, y_pred_nsen)\n",
    "    \n",
    "    all_labels = y_sen_label.append(y_nsen_label)\n",
    "    all_preds = y_pred_sen.append(y_pred_nsen)\n",
    "    total_accuracy = accuracy_score(all_preds, all_labels)\n",
    "    \n",
    "    print(\"The overall accuracy  is: \", total_accuracy)\n",
    "    print(\"The accuracy for African-American  is: \", acc_sen)\n",
    "    print(\"The accuracy for Caucasian  is: \", acc_nsen)\n",
    "    print(\"The calibration of the model is: \", abs(acc_sen-acc_nsen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LFR function \n",
    "#get train /validation accuracy\n",
    "def LFR(training_data, val_data, y_name, sen_variable_name, K, A_z, A_x, A_y):\n",
    "    # dividing the training dataset into sensitive and nonsensitive group\n",
    "    sen_training = training_data[training_data[sen_variable_name]==0]\n",
    "    nsen_training = training_data[training_data[sen_variable_name]==1]\n",
    "    \n",
    "    # dividing the validation dataset \n",
    "    sen_val = val_data[val_data[sen_variable_name]==0]\n",
    "    nsen_val = val_data[val_data[sen_variable_name]==1]\n",
    "    \n",
    "    # delete sensitive variable \n",
    "    sen_training=sen_training.drop(columns=[sen_variable_name])\n",
    "    sen_val=sen_val.drop(columns=[sen_variable_name])  \n",
    "    nsen_training = nsen_training.drop(columns=[sen_variable_name])\n",
    "    nsen_val = nsen_val.drop(columns=[sen_variable_name])\n",
    "    \n",
    "    # assign y labels \n",
    "    y_sen_training = sen_training[y_name]\n",
    "    sen_training = sen_training.drop(columns=[y_name])\n",
    "    y_sen_val = sen_val[y_name]\n",
    "    sen_val = sen_val.drop(columns=[y_name])\n",
    "    y_nsen_training = nsen_training[y_name]\n",
    "    nsen_training = nsen_training.drop(columns=[y_name])\n",
    "    y_nsen_val = nsen_val[y_name]\n",
    "    nsen_val = nsen_val.drop(columns=[y_name])\n",
    "    \n",
    "    # pick random value\n",
    "    # talpha and w  are between 0 and 1 and sum up to 1\n",
    "    alpha_sen_1=np.random.random_sample((sen_training.shape[1],))\n",
    "    alpha_nsen_1=np.random.random_sample((nsen_training.shape[1],))\n",
    "    alpha_sen=alpha_sen_1/sum(alpha_sen_1)\n",
    "    alpha_nsen=alpha_nsen_1/sum(alpha_nsen_1)\n",
    "    w_1=np.random.random_sample((K,))\n",
    "    w=w_1/sum(w_1)\n",
    "    v=np.random.random((K, sen_training.shape[1]))\n",
    "    \n",
    "    \n",
    "    initial = []\n",
    "    initial.extend(alpha_sen)\n",
    "    initial.extend(alpha_nsen)\n",
    "    initial.extend(w)\n",
    "    \n",
    "    for item in v:\n",
    "        initial.extend(item)\n",
    "    initial = np.array(initial)\n",
    "\n",
    "    # the boundary of the parameters\n",
    "    bound=[]\n",
    "\n",
    "    #  alpha and w are between 0 and 1 and sum up to 1\n",
    "    for d in range(sen_training.shape[1]):\n",
    "        bound.append((0, 1))\n",
    "\n",
    "    for d in range(nsen_training.shape[1]):\n",
    "        bound.append((0, 1))\n",
    "\n",
    "    for k in range(K):\n",
    "        bound.append((0, 1))\n",
    "\n",
    "    \n",
    "    for k in range(K):\n",
    "        for d in range(sen_training.shape[1]):\n",
    "            bound.append((None, None))\n",
    "    \n",
    "    # minimize the metric \n",
    "    para, min_L, d = optim.fmin_l_bfgs_b(L, x0=initial, epsilon=1e-5, \n",
    "                                         args=(sen_training, nsen_training, y_sen_training, \n",
    "                                               y_nsen_training, K, A_z, A_x, A_y), \n",
    "                                         bounds = bound, approx_grad=True, \n",
    "                                         maxfun=150000, maxiter=150000)\n",
    "    \n",
    "    # predict y_n_hat for the training dataset \n",
    "    y_hat_sen_tr, y_hat_nsen_tr = cal_pred(para, sen_training.shape[1], K, sen_training, \n",
    "             nsen_training, y_sen_training, y_nsen_training)\n",
    "\n",
    "    print(\" training accuracy:\")\n",
    "    cal_calibr(y_hat_sen_tr, y_hat_nsen_tr, y_sen_training, y_nsen_training)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # predict y_n_hat for the validation dataset \n",
    "    y_hat_sen_val, y_hat_nsen_val = cal_pred(para, sen_val.shape[1], K, sen_val, \n",
    "             nsen_val, y_sen_val, y_nsen_val)  \n",
    "    print(\"validation accuracy:\")\n",
    "    cal_calibr(y_hat_sen_val, y_hat_nsen_val, y_sen_val, y_nsen_val)    \n",
    "    \n",
    "    return  para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fk/z7v3jbsd74q31y7nyk6xvmj80000gn/T/ipykernel_25954/2372853154.py:13: RuntimeWarning: divide by zero encountered in log\n",
      "  L_y += (-1)*y.iloc[n]*np.log(y_n_hat[n]) - (1 - y.iloc[n])*np.log(1 - y_n_hat[n])\n",
      "/var/folders/fk/z7v3jbsd74q31y7nyk6xvmj80000gn/T/ipykernel_25954/2372853154.py:13: RuntimeWarning: invalid value encountered in multiply\n",
      "  L_y += (-1)*y.iloc[n]*np.log(y_n_hat[n]) - (1 - y.iloc[n])*np.log(1 - y_n_hat[n])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training accuracy:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fk/z7v3jbsd74q31y7nyk6xvmj80000gn/T/ipykernel_25954/3778343658.py:16: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_labels = y_sen_label.append(y_nsen_label)\n",
      "/var/folders/fk/z7v3jbsd74q31y7nyk6xvmj80000gn/T/ipykernel_25954/3778343658.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_preds = y_pred_sen.append(y_pred_nsen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall accuracy  is:  0.9\n",
      "The accuracy for African-American  is:  0.8333333333333334\n",
      "The accuracy for Caucasian  is:  1.0\n",
      "The calibration of the model is:  0.16666666666666663\n",
      "++++++++++++++++++++++++++++\n",
      "validation accuracy:\n",
      "For the validation set:\n",
      "The overall accuracy  is:  0.6246830092983939\n",
      "The accuracy for African-American  is:  0.6139860139860139\n",
      "The accuracy for Caucasian  is:  0.6410256410256411\n",
      "The calibration of the model is:  0.027039627039627145\n",
      "The training time: 1093.6725301742554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fk/z7v3jbsd74q31y7nyk6xvmj80000gn/T/ipykernel_25954/3778343658.py:16: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_labels = y_sen_label.append(y_nsen_label)\n",
      "/var/folders/fk/z7v3jbsd74q31y7nyk6xvmj80000gn/T/ipykernel_25954/3778343658.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_preds = y_pred_sen.append(y_pred_nsen)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "para_test = LFR(data_train, data_val, 'two_year_recid', 'race', 10, 0.3, 0.3, 0.4)\n",
    "end = time.time() \n",
    "print( f\"The training time: {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing time: 4.76779317855835\n",
      "The overall accuracy  is:  0.665257819103973\n",
      "The accuracy for African-American  is:  0.6494413407821229\n",
      "The accuracy for Caucasian  is:  0.6895074946466809\n",
      "The calibration of the model is:  0.04006615386455803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fk/z7v3jbsd74q31y7nyk6xvmj80000gn/T/ipykernel_25954/3778343658.py:16: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_labels = y_sen_label.append(y_nsen_label)\n",
      "/var/folders/fk/z7v3jbsd74q31y7nyk6xvmj80000gn/T/ipykernel_25954/3778343658.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_preds = y_pred_sen.append(y_pred_nsen)\n"
     ]
    }
   ],
   "source": [
    "# Testing the LFR model\n",
    "sen_test = data_test[data_test['race']==0]\n",
    "nsen_test = data_test[data_test['race']==1]\n",
    "\n",
    "sen_test=sen_test.drop(columns=['race'])\n",
    "nsen_test = nsen_test.drop(columns=['race'])\n",
    "\n",
    "y_sen_test = sen_test['two_year_recid']\n",
    "sen_test = sen_test.drop(columns=['two_year_recid'])\n",
    "\n",
    "y_nsen_test = nsen_test['two_year_recid']\n",
    "nsen_test = nsen_test.drop(columns=['two_year_recid'])\n",
    "\n",
    "start = time.time()\n",
    "y_hat_sen_test, y_hat_nsen_test = cal_pred(para_test, sen_test.shape[1], 10, sen_test, \n",
    "             nsen_test, y_sen_test, y_nsen_test)\n",
    "end = time.time() \n",
    "print( f\"runtime of testing LFR model: {end-start}\")\n",
    "cal_calibr(y_hat_sen_test, y_hat_nsen_test, y_sen_test, y_nsen_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximizing fairness under accuracy constriants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/optimization-with-scipy-and-application-ideas-to-machine-learning-81d39c7938b8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
